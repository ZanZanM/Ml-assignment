# -*- coding: utf-8 -*-
"""Copy of assignment3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vLJFeLsxWCSgQ57rKCWEOKhma7OtnulD

# Assignment 3
"""

from google.colab import drive
drive.mount('/content/drive')

"""## 1. Import Libraries"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd

import nltk
import string
from tqdm import tqdm
import plotly.express as px
import matplotlib.pyplot as plt
from bs4 import BeautifulSoup

from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer
from nltk.tokenize import sent_tokenize, word_tokenize

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neural_network import MLPClassifier
from sklearn import metrics
from sklearn.metrics import accuracy_score, classification_report
from mlxtend.plotting import plot_confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from prettytable import PrettyTable

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')

ps = PorterStemmer()
STOPWORD = set(stopwords.words('english'))

"""## 2. Import Data"""

review_df = pd.read_csv("/content/drive/MyDrive/zane/IMDB Dataset.csv")  ## reading data using read_csv method
print("Shape of the IMDB review dataset is {}.".format(review_df.shape)) ## getting shape of the dataset
review_df.head(3)

"""## 3. Data Cleaning 

This process invloves removal of duplicate rows, removal/imputation of null values, anomaly detection etc. 
"""

## null value analysis
review_df.isnull().sum()

## duplicate values
review_df[review_df.duplicated()]

"""* There are no null values present in the dataset.
* There are 418 rows present as duplicate rows in the dataset.
* To avoid redundency we must remove the duplicate rows.
"""

## dropping duplicates
review_df1 = review_df.drop_duplicates()
print("Shape after dropping the duplicate rows from dataset is {}.".format(review_df1.shape))

"""## 4. Target Label Analysis"""

## pie plot for target data
fig = px.pie(review_df1, names= "sentiment", color_discrete_sequence = ['cyan', 'darkblue'])
fig.show()

"""* As we can see above the output class is highly balanced and both positive and negative sentiments are equally distributed.

## 5. Splitting of data

* As given in the instruction we must split the review data equally between train and test set which is 25k. Since I have removed some duplicate I will split it equally.
"""

## mapping of output (positive review 1, negative review 0)
review_df1["sentiment_label"] = review_df1["sentiment"].map({"positive":1, "negative":0})

y = review_df1["sentiment_label"].values
X = review_df1.drop(columns = "sentiment_label")

## splitting the data
xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.50, random_state=42, stratify=y)

## getting shape
print("Shape of xtrain, xtest, ytrain and ytest is {}, {}, {}, and {} respectively.".format(xtrain.shape, 
                                                                                           xtest.shape,
                                                                                           ytrain.shape,
                                                                                           ytest.shape))

"""## 5.  Text Preprocessing

Now that I have finished cleaning, our data requires some preprocessing before we go on further with analysis and making the prediction model.

From the initial analysis we found that dataset contains html tags as well.

Hence in the Preprocessing phase I am doing the following in the order below:

1. removal of html tags
2. lowercasing the text to avoid the same word with different representation
3. removal of punctuations
4. removal of stopwords
5. removal of all digits
6. stemming the words into its root
"""

review_df1["review"].values[10]

BeautifulSoup(review_df1["review"].values[10], 'lxml').get_text()

## cleaning text
xtrain['clean_review'] = xtrain['review'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())
xtest['clean_review'] = xtest['review'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())

## lowercasing the text
xtrain['clean_review'] = xtrain['clean_review'].apply(lambda x:x.lower())
xtest['clean_review'] = xtest['clean_review'].apply(lambda x:x.lower())

## removal of punctuations
xtrain['clean_review'] = xtrain['clean_review'].apply(lambda x: "".join(i for i in x if i not in string.punctuation))
xtest['clean_review'] = xtest['clean_review'].apply(lambda x: "".join(i for i in x if i not in string.punctuation))

## removal of stop words
xtrain['clean_review'] = xtrain['clean_review'].apply(lambda x: " ".join(i for i in word_tokenize(x) if i not in STOPWORD))
xtest['clean_review'] = xtest['clean_review'].apply(lambda x: " ".join(i for i in word_tokenize(x) if i not in STOPWORD))

## removal of all numbers present in the test
xtrain['clean_review'] = xtrain['clean_review'].apply(lambda x: " ".join(i for i in word_tokenize(x) if i.isdigit()!=True))
xtest['clean_review'] = xtest['clean_review'].apply(lambda x: " ".join(i for i in word_tokenize(x) if i.isdigit()!=True))

## stemming of words into it's original form
xtrain['clean_review'] = xtrain['clean_review'].apply(lambda x: " ".join(ps.stem(i) for i in word_tokenize(x)))
xtest['clean_review'] = xtest['clean_review'].apply(lambda x: " ".join(ps.stem(i) for i in word_tokenize(x)))

xtrain['review'].values[2]

xtrain['clean_review'].values[2]

"""## 6. Encoding of the text using tfidf vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer

## intilializing tf-idf object with ngram range till 3 and minimum repetition of word in the text corpus as 10
tfidf = TfidfVectorizer(ngram_range=(1,3), min_df=10, max_df=0.9, use_idf=True, smooth_idf=True)

##fitting and transforming the text data for train data
xtrain_text = tfidf.fit_transform(xtrain['clean_review'])
## transforming test data
xtest_text = tfidf.transform(xtest['clean_review'])

## getting shape
print(xtrain_text.shape, xtest_text.shape)

"""## 7. Task 2

"""

## building a one layer multi layer perceptron
## there is only one layer with 64 neurons and activation type is "ReLU"
clf_model1 = MLPClassifier(activation='relu', hidden_layer_sizes=(64), alpha = 0.1, max_iter=100).fit(xtrain_text, ytrain)

## predicting output
ypred_model1 = clf_model1.predict(xtest_text)

## train test scores
acc_train_model1 = clf_model1.score(xtrain_text, ytrain)
print('Training Acc : {:.4f}.'.format(acc_train_model1))

## accuracy scores
accuracy_model1, f1score_model1 = metrics.accuracy_score(ytest, ypred_model1), metrics.f1_score(ytest, ypred_model1)
precision_model1, recall_model1 = metrics.precision_score(ytest, ypred_model1),metrics.recall_score(ytest, ypred_model1)                                                                                         
print("test acc -- {:.4f}, fscore -- {:.4f}, precision -- {:.4f}, recall -- {:.4f}.".format(accuracy_model1, f1score_model1, 
                                                                                            precision_model1, recall_model1))

## confusion matrix
fig, ax = plot_confusion_matrix(conf_mat = metrics.confusion_matrix(ytest, ypred_model1), figsize=(5, 5))
plt.xlabel("Predicted Class", fontsize=15)
plt.ylabel("Actual Class", fontsize=15)
plt.title("Confusion Matrix", fontsize=15)
plt.show()

"""## 8. Task 3

"""

## building a one layer multi layer perceptron
## there are two layers with 64 and 32 neurons respectively with ReLU activation
clf_model2 = MLPClassifier(activation='relu', hidden_layer_sizes=(64,32), alpha = 0.1, max_iter=100).fit(xtrain_text, ytrain)

## predicting output
ypred_model2 = clf_model2.predict(xtest_text)

## train test scores
acc_train_model2 = clf_model2.score(xtrain_text, ytrain)
print('training acc for model 2 is : {:.4f}.'.format(acc_train_model2))

## accuracy scores
accuracy_model2, f1score_model2 = metrics.accuracy_score(ytest, ypred_model2), metrics.f1_score(ytest, ypred_model2)
precision_model2, recall_model2 = metrics.precision_score(ytest, ypred_model2),metrics.recall_score(ytest, ypred_model2)

print("test acc -- {:.4f}, fscore -- {:.4f}, precision -- {:.4f}, recall -- {:.4f}.".format(accuracy_model2, f1score_model2, 
                                                                                            precision_model2, recall_model2))

## confusion matrix
fig, ax = plot_confusion_matrix(conf_mat=metrics.confusion_matrix(ytest, ypred_model2), figsize=(5, 5))
plt.xlabel("Predicted Class", fontsize=15)
plt.ylabel("Actual Class", fontsize=15)
plt.title("Confusion Matrix", fontsize=15)
plt.show()

"""## 9. Task 4
* Finally, compare your neural models with at least one traditional classification algorithm. 
"""

## as a traditional algorithm I am going to use decision tree 
clf_dt = DecisionTreeClassifier(random_state=42)

## initializing parameters
param_dt = {'max_depth':[50, 100, 200],
            'min_samples_split':[100, 200, 300], 
            'min_samples_leaf':[1,3,5],
            'max_leaf_nodes':[1,3,5, None]}

# hyper parameter tuning
clf = GridSearchCV(clf_dt, param_dt, 
                   cv=3, scoring='roc_auc', 
                   return_train_score=True, 
                   verbose=5,
                   n_jobs=-1).fit(xtrain_text, ytrain)

print("Best cross-validation score: {:.2f}".format(clf.best_score_))
print("Best parameters: ", clf.best_params_)

## predicting with best parameters
clf_dt = DecisionTreeClassifier(max_depth = clf.best_params_['max_depth'], 
                               min_samples_split = clf.best_params_['min_samples_split'], 
                               max_leaf_nodes = clf.best_params_['max_leaf_nodes'],
                               min_samples_leaf = clf.best_params_['min_samples_leaf'],
                               random_state=42).fit(xtrain_text, ytrain)

## predicting output
ypred_dt = clf_dt.predict(xtest_text)

## train test scores
acc_train_dt = clf_dt.score(xtrain_text, ytrain)
print('Training Acc  : {:.4f}.'.format(acc_train_dt))

## accuracy scores
accuracy_dt, f1score_dt = metrics.accuracy_score(ytest, ypred_dt), metrics.f1_score(ytest, ypred_dt)
precision_dt, recall_dt = metrics.precision_score(ytest, ypred_dt),metrics.recall_score(ytest, ypred_dt)

print("test_acc -- {:.4f}, fscore -- {:.4f}, precision -- {:.4f}, recall -- {:.4f}.".format(accuracy_dt, f1score_dt,
                                                                                              precision_dt, recall_dt))

## confusion matrix
fig, ax = plot_confusion_matrix(conf_mat = metrics.confusion_matrix(ytest, ypred_dt), figsize=(5, 5))
plt.xlabel("Predicted Class", fontsize=15)
plt.ylabel("Actual Class", fontsize=15)
plt.title("Confusion Matrix", fontsize=15)
plt.show()

"""## 10. Comparison"""

## creating pretty table to show the values
table = PrettyTable()

table.field_names = ["model_names", "train_acc",  "test_acc", "fscore", "precision", "recall"]

table.add_row(["1-layer MLP", acc_train_model1, accuracy_model1, f1score_model1, precision_model1, recall_model1])
table.add_row(["2-layer MLP", acc_train_model2, accuracy_model2, f1score_model2, precision_model2, recall_model2])
table.add_row(["Decision Tree", acc_train_dt, accuracy_dt, f1score_dt, precision_dt, recall_dt])

print(table)

def frequent_words(data, num_of_words):
    """
    This function provides the frequent words present in the text corpus.
    """
    #Creating a list of words present in the all text corpus
    corpus = [j for line in data.values for j in line.split()]

    ## using Counter method to create word_count of each unique word
    word_count = Counter(corpus)

    ## getting top n most common words
    n_words = word_count.most_common(num_of_words)

    return n_words


def plot_for_word_n_count(words, counts, size, label):

    ## bar plot using matplotlib
    fig = plt.figure(figsize=size)
    plot = plt.barh(words, counts, 0.75, color = "black")

    ## getting number count for each bar
    for i, v in enumerate(counts):
        plt.text(v + 1, i - 0.20, str(v), color='black', fontweight='bold')

    ## title, labels
    plt.title("word analysis", fontsize=15)
    plt.xlabel(label, fontsize=15)
    plt.ylabel("count", fontsize=15)
    plt.show()

from collections import Counter

## for positive features we have select only those reviews where evaluation is greater than 0
df_positive = xtrain[xtrain["sentiment"] == "negative"]

## getting top 10 positive words
postive_words = frequent_words(df_positive["clean_review"], 10)

## plot
pos_data = pd.DataFrame(postive_words)
plot_for_word_n_count(list(pos_data.iloc[:,0].values), list(pos_data.iloc[:,1].values), (15,5), "positive words")

xtrain